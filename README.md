# churn_model
Overview
Instructions for Python Notebook:
1.	The code for all the methods tried and tested is included in the jupyter notebook with comments.
2.	The file contains a section at the end named as “Churn Model”. It includes the step by step procedure of extracting the data, defining the features, scaling the data and running the final model.
3.	The code for all the models (Random Forest, SVM etc.) including their temporal hold out evaluation is under their respective headings.
Instructions for Figures:
1.	Fig 1.1 is created in jupyter notebook. It is a correlation matrix. The code can be found under the feature selection heading.
2.	Fig 2.1, 2.2, 2.3 and 2.4 are created in Tableau using the excel files. The excel files were created in python under the section “Customer Insights. These files were imported into Tableau to create the graphs.
3.	The figures of confusion matrix of all models as well as the classification reports are made in python. Seaborn library has been used to create the confusion matrix and sklearn metrics were used to generate the classification report. 
Instructions for Excel Files:
1.	The excel file named “ucd_data” has been created as a result of an SQL query. This file was created to be used for customer insights analysis. The code can be found under the “Customer Insights” section in the python notebook.
2.	The excel files named “data1”, “churners” and “non_churners” were also created to make graphs in tableau. Their codes are also included in the python notebook.

Data Cleaning:
No additional data cleaning was undertaken.
